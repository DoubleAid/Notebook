## 正则化层： 加快模型的产生速度
BatchNormal2d 输入只需要指定 channel

## Recurrent Layers：写好的特定的网络层

## Transformer Layer: 写好的特定层

## Linear Layer: 线性层，结点的线性网络

## Dropout Layer: 训练过程中随机取点某些输入， 防止过拟合

## Sparse Layer：
