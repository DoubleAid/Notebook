# PointNet 模型解读

## PointNet 基本出发点

由于点的无序性导致，需要模型具有置换不变性

$f(x_1, x_2, ..., x_n)$ = f(x_{p_1}, x_{p_2}, ..., x_{p_n}), x_i

例如下列公式，但是如何在神经网络中体现呢

f(x1, x2, ..., xn) = max{x1, x2, ..., xn}
f(x1, x2, ..., xn) = x1 + x2 + ... + xn

### 基本出发点

直接利用max函数计算各个维度的最大值，但是损失的特征太多了，能不能先升维后再做max操作（其实就是神经网络的隐层）

所以就是 f(x1, x2, ..., xn) = r * g(h(x1), h(x2), ..., h(xn))

也就是对每个样本点先进行升维，然后再操作

```python
data = [
    [1,2,3],
    [1,1,1],
    [2,3,2],
    ...,
    [2,3,4],
]

# 使用多层感知机 MLP 进行升层(卷积或者全连接)
data = MLP(data)
# max 得到全局
data = max(data)
# 在进行映射
data = MLP(data)
```

### 整体网络架构

```python
# 分类网络
[nx3] -> input transform -> [nx3] -> mlp(64,64) -> [nx64] -> mlp(64, 128, 1024) -> [nx1024] -> max_pool
-> [1024] -> mlp(512, 256, k) -> [k] output scores

# 分割网络
[nx3] -> input transform -> [nx3] -> mlp(64,64) -> [nx64] -> mlp(64, 128, 1024) -> [nx1024] -> max_pool
-> [1024] + [nx64] -> [nx1088] -> mlp(512, 256, 128) -> [nx128] -> mlp(128, m) -> [nxm] output scores
```

## PointNet++

### PointNet的问题 --> PointNet++

+ 跟当下主流网络不符，没有局部特征融合，要不自己，要么就是整体
+ 没有关系概念，局部样本点之间肯定存在关系的，没有考虑到
+ PointNet++版本要从局部入手，多利用局部特征
+ 整体思想不变，只不过在特征提取处使用类似图卷积的方式来整合特征

### 基本出发点

+ 基于半径选择局部区域（类似得到多个簇）
+ 针对得到的每个区域进行特征提取（卷积）
+ 要解决的问题：如何选择区域，（簇中心点的选择）
+ 簇的半径大小如何定义，每个簇中选择多少个样本点

#### 最远点采样：第一步先确定好每一个局部区域，接下来对局部区域执行 pointnet

选取一个区域，对区域里的点进行 pointnet， 得到一个特征向量

例如输入1024点，要选择128个中心点（簇），如何进行采样呢 --> 最远点采样

在选取每个点的时候，选择离当前点最远的点，多个点时选择距离多个点最小值最大的点

保证尽可能覆盖图像的所有区域

#### 分组 （grouping）

例如： 输入为batch*1024*6 即 1024个点，每个6个值对应3个坐标3个法向量信息

分组后输出为 batch*128*16*6 （128个中心点，每个簇16个样本）

实际计算时选择多种半径，多种样本点个数，目的是特征更丰富

例如：半径 = （0.1，0.2，0.4）对应的簇的样本个数（16，32，64），将计算的特征进行拼接 [0.1半径特征][0.2半径特征][0.4半径特征]

每个簇里选择的点，如果有的簇的点多，有的簇的点少，该如何添加点呢

+ 如果点少的话，就复制距离中心点最近的点
+ 如果点太多的话，选取距离中心点最近的n个点



