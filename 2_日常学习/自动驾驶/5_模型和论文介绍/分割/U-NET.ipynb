{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9742243-7e54-42af-8504-16f7420d7f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8200b44-55ed-45c3-ae77-0850fc3809e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "input = torch.tensor([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9],\n",
    "])\n",
    "\n",
    "print(input.shape)\n",
    "\n",
    "kernel = torch.tensor([\n",
    "    [1, 0],\n",
    "    [0, 2],\n",
    "])\n",
    "\n",
    "print(kernel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68998f22-d4bf-4b91-b824-ad86b28ef745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5096,  1.5096,  2.5096, -0.4904],\n",
      "        [ 3.5096,  6.5096,  9.5096,  5.5096],\n",
      "        [ 6.5096, 15.5096, 18.5096, 11.5096],\n",
      "        [-0.4904, 13.5096, 15.5096, 17.5096]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# 定义输入特征图\n",
    "input = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "]).unsqueeze(0).unsqueeze(0).float()\n",
    "\n",
    "# 定义 ConvTranspose2d 层\n",
    "conv_transpose = nn.ConvTranspose2d(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    kernel_size=2,\n",
    "    stride=1,\n",
    "    padding=0,\n",
    "    output_padding=0\n",
    ")\n",
    "\n",
    "# 定义卷积核\n",
    "conv_transpose.weight.data = torch.tensor([\n",
    "    [1, 0],\n",
    "    [0, 2]\n",
    "]).unsqueeze(0).unsqueeze(0).float()\n",
    "\n",
    "# 计算输出特征图\n",
    "output = conv_transpose(input)\n",
    "\n",
    "# 打印输出特征图\n",
    "print(output.squeeze(0).squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe3b132-c856-4cdd-ac60-28d524dd959e",
   "metadata": {},
   "source": [
    "转置卷积（也称为反卷积）并不是卷积操作的严格逆向操作。虽然它们在某些情况下看起来相似，但它们的数学定义和用途有所不同。让我们详细解释一下。\n",
    "卷积操作\n",
    "卷积操作是将一个卷积核（或滤波器）滑动到输入特征图上，计算每个位置的点积，从而生成一个较小的输出特征图。卷积操作通常用于提取特征。\n",
    "假设输入特征图 A 的大小为 H×W，卷积核 K 的大小为 k×k，步长为 s，填充为 p，则输出特征图 B 的大小为：\n",
    "H \n",
    "out\n",
    "​\n",
    " =⌊ \n",
    "s\n",
    "H+2p−k\n",
    "​\n",
    " +1⌋\n",
    "W \n",
    "out\n",
    "​\n",
    " =⌊ \n",
    "s\n",
    "W+2p−k\n",
    "​\n",
    " +1⌋\n",
    "转置卷积操作\n",
    "转置卷积操作的目的是将特征图上采样，生成一个较大的输出特征图。它通过在输入特征图的每个元素周围插入零值（或使用其他填充方式），然后应用卷积核来生成输出特征图。\n",
    "假设输入特征图 B 的大小为 H \n",
    "in\n",
    "​\n",
    " ×W \n",
    "in\n",
    "​\n",
    " ，卷积核 K 的大小为 k×k，步长为 s，填充为 p，输出填充为 op，则输出特征图 A 的大小为：\n",
    "H \n",
    "out\n",
    "​\n",
    " =(H \n",
    "in\n",
    "​\n",
    " −1)×s−2p+k+op\n",
    "W \n",
    "out\n",
    "​\n",
    " =(W \n",
    "in\n",
    "​\n",
    " −1)×s−2p+k+op\n",
    "转置卷积不是卷积的逆操作\n",
    "虽然转置卷积可以在某些情况下用于上采样，但它并不是卷积操作的严格逆操作。原因如下：\n",
    "信息丢失：卷积操作通常会丢失一些信息（例如，边界信息），因为卷积核的滑动会导致输出特征图的大小减小。转置卷积无法完全恢复这些丢失的信息。\n",
    "数学定义不同：转置卷积的数学定义是通过在输入特征图周围插入零值，然后应用卷积核，而不是简单地“反转”卷积操作。\n",
    "参数不同：转置卷积需要额外的参数（如输出填充 output_padding），这些参数在卷积操作中并不存在。\n",
    "示例\n",
    "假设我们有一个 3×3 的输入特征图 A 和一个 2×2 的卷积核 K，步长为 1，填充为 0。卷积操作的结果 B 是一个 2×2 的特征图。\n",
    "A= \n",
    "​\n",
    "  \n",
    "1\n",
    "4\n",
    "7\n",
    "​\n",
    "  \n",
    "2\n",
    "5\n",
    "8\n",
    "​\n",
    "  \n",
    "3\n",
    "6\n",
    "9\n",
    "​\n",
    "  \n",
    "​\n",
    " \n",
    "K=[ \n",
    "1\n",
    "0\n",
    "​\n",
    "  \n",
    "0\n",
    "2\n",
    "​\n",
    " ]\n",
    "卷积操作的结果 B 为：\n",
    "B=[ \n",
    "11\n",
    "20\n",
    "​\n",
    "  \n",
    "14\n",
    "23\n",
    "​\n",
    " ]\n",
    "现在，我们尝试使用转置卷积将 B 上采样回 A 的大小。假设我们使用相同的卷积核 K，步长为 1，填充为 0，输出填充为 0。转置卷积的结果 A \n",
    "′\n",
    "  为：\n",
    "A \n",
    "′\n",
    " = \n",
    "​\n",
    "  \n",
    "11\n",
    "20\n",
    "0\n",
    "​\n",
    "  \n",
    "14\n",
    "23\n",
    "0\n",
    "​\n",
    "  \n",
    "0\n",
    "0\n",
    "0\n",
    "​\n",
    "  \n",
    "​\n",
    " \n",
    "可以看到，A \n",
    "′\n",
    "  并不等于原始的 A。这是因为转置卷积无法完全恢复卷积操作中丢失的信息。\n",
    "总结\n",
    "转置卷积并不是卷积操作的严格逆操作。虽然它们在某些情况下看起来相似，但它们的数学定义和用途有所不同。转置卷积主要用于上采样，而不是恢复卷积操作的结果。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
