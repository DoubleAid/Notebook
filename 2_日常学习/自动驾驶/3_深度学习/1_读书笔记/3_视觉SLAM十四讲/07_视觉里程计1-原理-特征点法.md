# 视觉里程计 1

## 主要目标

1. 理解图像特征点的意义，掌握单幅图像中提取特征点及多幅图像中匹配特征点的方法
2. 理解对极几何的原理，利用对极几何的约束，恢复出图像之间的摄像机的三维运动
3. 理解PNP问题，以及利用已知三维结构与图像的对应关系求解摄像机的三维运动
4. 理解IPC问题，以及利用点云的匹配关系求解摄像机的三维运动
5. 理解如何通过三角化获得二维图像上对应点的三维结构

## 特征点法

之前我们已经讲过，视觉SLAM主要分为视觉前端和优化后端，前端也称为视觉里程计（VO）。它的主要功能是根据相邻图像的信息估计出粗略的相机运动，给后端提供较好的初始值。VO的实现方法，按照是否需要提取特征，分为特征点伐的前端以及不提特征的直接法前端。基于特征法的前端是视觉里程计的主流方法。它运行稳定，对光照，动态物体不敏感。

提取，匹配图像特征点 --> 估计两帧之间的相机运动和场景结构

### 特征点

特征点就是图像中一些特别的地方，如角点，边缘，区块

识别的困难度 角点 < 边缘 < 区块

但是角点在移动或旋转后不容易辨别，为此设计出许多更加稳定的局部图像特征

+ SIFT
+ SURF
+ ORB

相比于朴素的角点，人工设计的特征点拥有如下性质

1. 可重复性：相同的区域可以在不同的图像中找到
2. 可区别性：不同的区域有不同的表达
3. 高效率：在同一图像中，特征点的数量应远小于像素的数量
4. 本地行：特征仅与一小片图像区域相关

特征点有 关键点 (key-point) 和描述子 (descriptor) 两部分组成
比如在谈论SIFT特征时，是指“提取SIFT关键点，并计算SIFT描述子”这两件事

+ 关键点是指该特征点在图像里的位置，有一些特征点还具有朝向，大小等信息
+ 描述子通常是一个向量，按照某种认为设计的方式，描述了该关键点周围像素的信息

描述子是按照 “外观相似的特征该有相似的描述子” 的原则设计，因此只要两个特征点的描述子在向量空间上的距离相近，就可以认为它们是同样的特征点

+ SIFT（尺度不变特征变换， Scale-Invariant Feature Transform）是最经典的一种，他充分考虑了光照，尺度，旋转等变化，但是计算量极大
+ FAST 考虑适当降低精度和健壮性，FAST关键点属于计算特别快的一种特征点（没有描述子）
+ ORB (Oriented FAST and Rotated BRIEF) 特征则是目前看来非常具有代表性的实时图像特征。它改进了FAST检测子不具有方向性的问题，并采用速度极快的二进制描述子BRIEF，使整个图像特征提取的环节大大加速

提取过程具有很好的并行性，可以通过GPU等设备来加速计算

### ORB特征

ORB 特征保持了特征子具有旋转，尺度不变形的同时，速度方面提升明显

ORB 也是由 关键点和描述子 两部分组成，他的关键点称为 "Oriented Fast", 是一种改进的FAST角点，
他的描述子称为 BRIEF (Binary Robust Independent Elementary Feature)
提取ORB特征分为如下步骤：

1. FAST 角点提取：找到图像中的"角点"。相较于原版的FAST，ORB中计算了特征点的主方向，为后续的BRIEF描述子增加了旋转不变特性
2. BRIEF描述子：对前一步提取出特征点的周围图像区域进行描述

接下来分别介绍 FAST 和 BRIEF

#### FAST 关键点

FAST是一种角点，主要检测局部像素灰度变化明显的地方，以速度快著称。它的思想是： 如果一个像素与相邻的像素差别过大（过亮或者过暗），那么他可能是角点

1. 在图像中选取像素p，假设它的亮度是 $l_p$
2. 设置一个阈值T，（比如，$l_p$ 的20%）
3. 以像素p为中心，选取半径为3的圆上的16个像素点
4. 加入选取的圆上有连续的N个点大于 $l_p + T$ 或 小于$l_p - T$, 那么像素p可以被认为是特征点 (N 通常是 12， 即 FAST-12。 其他常用的N取值为9和11，分别称为 FAST-9 和 FAST-11)
5. 循环以上四步，对每一个像素执行相同的操作

在FAST-12算法中，为了更高效，可以添加一项预测试操作，以快速排除绝大多数不是角点的像素。具体操作是对于每一个像素，直接检测邻域圆上的第1，5， 9， 13个像素的亮度，只有这4个像素中有三个同时满足条件时，当前像素才可能是一个角点，这样可以大大加速角点检测

+ 原始的FAST角点经常出现扎堆的现象，所以在第一次检测之后，还需要用非极大值抑制   (Non-maximal suppression), 在一定区域内仅保留响应极大值的角点，避免角点集中的问题
    + 按照置信度排序，置信度可以按照中心像素和周围16像素点的亮度差的绝对值
    + 选择置信度最高的点作为最优值
    + 计算重叠度
    + 移除重叠框中置信度较低的点
+ FAST特征点数量很大且不确定，而我们往往希望对图像提取固定数量的特征。我们可以指定最终要提取的角点数量N，对原始FAST角点分别计算Harris响应值，然后选取前N个具有最大响应值的角点作为最终的角点集合
+ FAST角点不具有方向信息。而且它固定取半径为3的圆，存在尺度问题：远看是角点的地方，接近后就不是角点了
    + 尺度不变形由构建图像金字塔，并在金字塔的每一层上检测角点来实现
    + 而特征的旋转是由灰度质心法实现的

通过上述方法，FAST焦点便具有了尺度和旋转的描述，从而大大提升了其在不同图像之间表述的健壮性

#### BRIEF 描述子

BRIEF是一种二进制描述子，其描述向量由许多0和1组成，这里的0和1编码了关键点附近两个像素p和q的大小关系：p大于q就选择0，否则就选择1，选取方法是按照概率分布随机选取

#### 特征匹配

特征匹配解决了SLAM中的数据关联问题 (data association)，即确定当前看到的路标和之前看到的路标之间的对应关系

通过图像和图像或者图像和地图之间的描述子进行准确匹配，可以为后续的姿态估计、优化等操作减轻大量负担。

但图像特征的局部特性，误匹配的情况广泛存在，而且长期以来没有得到有效的解决，部分场景经常出现大量重复的纹理，使得特征描述非常相似

但我们先考虑正确匹配的情况，最简单的方法就是暴力匹配法，即将当前帧的一个特征点和前一帧的所有特征点计算描述子的距离，在BRIEF中使用汉明距离，就是二进制不同位的个数

接下来，我们希望根据匹配的点对估计相机的云顶，这里由于相机的原理不同，情况发生了变换

1. 当相机为单目时，我们只知道2D的像素坐标，因而问题时根据两组2D点的运动，该问题使用对极几何来解决。
2. 当相机为双目，RGB-D时，或者通过某种方法得到了距离信息，那么问题就是根据两组3D点估计运动，这问题通常用ICP解决
3. 如果有3D点以及其在相机的投影位置，也能估计相机的运动。该问题通过PnP求解

## 2D-2D：对极几何

首先来看一下一对配对好的特征点有什么几何关系

当我们希望求取两帧图像 I_1, I_2之间运动，假设第一帧到第二帧的运动为 R，t，两个相机的中心分别为 $O_1, O_2$, 现在考虑$I_1$中的一个特征点$p_1$，在$I_2$中对应的特征点$p_2$，
+ 连接 $O_1, P_1$，得到向量 $\vec{P_1O_1}$，连接 $O_2, P_2$，得到向量 $\vec{P_2O_2}$, 这两个向量的延伸会在空间内交汇于P点，，
+ 将 $O_1, O_2, P$ 三点确定的平面称为极平面，记为 $\Pi$
+ $O_1, O_2$ 连线与平面 $I_1, I_2$ 分别交于 $e_1, e_2$,这两个点被称为极点
+ O_1O_2被称为基线，
+ 极平面和两个成像平面之间的相交线称为极线

假设P的空间位置是
$$
P = [X, Y, Z]^T
$$
根据第五讲介绍的针孔相机模型，我们知道两个像素点 $p_1, p_2$ 的像素位置
$$
s_1p_1 = KP, s2p2 = K(RP + t)
$$
这里 K 是相机内参矩阵，R，t 就是两个坐标系之间的相机运动，$s_1, s_2$ 是像素坐标系的尺度因子，在这种情况下两者是相同的，$p_1, p_2$ 是像素坐标，P是第一帧相机成像坐标下的位置

使用齐次坐标就显示成
$$
p_1=KP, p_2=K(RP + t)
$$

现在取$x_1, x_2$ 为 $p_1, p_2$ 的归一化坐标，即
$$
x_1 = \frac{p_1}{\|p_1\|}, x_2 = \frac{p_2}{\|p_2\|}
$$

根据针孔相机模型，我们有
$$
x_1 = K^{-1}p_1, x_2 = K^{-1}p_2 \\

x_2 = Rx_1 + t
$$
两边同时乘 $t \times$, 可以得到
$$
t \times x_2 = t \times Rx_1 + t \times t = t \times R x_1
$$

观察左侧，$t \times x_2$ 是一个与 $t 和 x_2$ 垂直的向量，再与x_2 作内积，就是两个向量投影到x_2上的长度，即为 0，因此
$$
x_2^Tt \times Rx_1 = 0
$$
重新代入$p_1, p_2$
$$
p_2^TK^{-T} t \times RK^-1p_1 = 0
$$

这两个式子都称为对极约束，他的几何意义就是$O_1,P,O_2$三点共面，$p_1$在归一化平面下旋转位移后的向量和$p_2$ 旋转位移后的向量垂直

我们把中间的部分计作两个矩阵，基础矩阵 (Fundamental Matrix) F 和本质矩阵 (Essential Matrix) E, 于是可以进一步简化对极约束
$$
E = t \times R \\
F = K^{-T}EK^{-1}
x_2^TEx_1 = p_2^TFp_1 = 0
$$

于是相机位姿估计就变成了以下两步
1. 根据配对点的像素位置求出E或者F
2. 根据E或者F求出R，t

在研究一下，其实K就是相机内参，这个我们很容易得到，所以所求的就是 本质矩阵

### 本质矩阵

本质矩阵 E 是一个3x3的矩阵，它描述了两个相机之间的相对运动，即相机1到相机2的旋转和平移。他有以下几个性质

+ 本质矩阵是由对极约束定义的，由于对极约束是等式为零的约束，所以本质矩阵的秩为2
+ 旋转和平移共有6个自由度，本质矩阵有9个元素，所以本质矩阵的秩为2

实际上就是五个自由度，因为他有五个自由度，我们至少需要五对点来进行求解，但为了减少解线性方程带来非复杂性，我们使用 8对点来估计E，这就是经典的八点法 (Eight-point-algorithm)

#### 八点法

考虑一对匹配点，它们的归一化坐标为 $x_1 = [u_1, v_1, 1]^T, x_2 = [u_2, v_2, 1]^T$。根据对极约束，有
$$
(u_1, v_1, 1) \begin{bmatrix}
    e_1 & e_2 & e_3 \\
    e_4 & e_5 & e_6 \\
    e_7 & e_8 & e_9
\end{bmatrix} \begin{bmatrix}
    u_2 \\
    v_2 \\
    1
\end{bmatrix} = 0
$$

将这个式子展开，可以得到一个关于 $e_i$ 的线性方程组，共有8对点，所以共有8个这样的方程，可以得到一个8x9的矩阵A，其中每一行对应一个方程，每一列对应一个 $e_i$，然后我们求解这个线性方程组，得到 $e_i$ 的值，然后我们对 $e_i$ 进行奇异值分解，得到本质矩阵 E
$$
e = [e_1, e_2, e_3, e_4, e_5, e_6, e_7, e_8, e_9]^T \\

[u_1u_2, u_1v_2, u_1, v_1u_2, v_1v_2, v_1, u_2, v_2, 1]e = 0
$$

我们把所有的点都放到一个方程里，就变成了
$$
\begin{bmatrix}
u_1^1u_2^1 & u_1^1v_2^1 & u_1^1 & v_1^1u_2^1 & v_1^1v_2^1 & v_1^1 & u_2^1 & v_2^1 & 1 \\
u_1^2u_2^2 & u_1^2v_2^2 & u_1^2 & v_1^2u_2^2 & v_1^2v_2^2 & v_1^2 & u_2^2 & v_2^2 & 1 \\
... & ... & ... & ... & ... & ... & ... & ... & ... \\
u_1^8u_2^8 & u_1^8v_2^8 & u_1^8 & v_1^8u_2^8 & v_1^8v_2^8 & v_1^8 & u_2^8 & v_2^8 & 1
\end{bmatrix}e = 0
$$

进行奇异值分解 SVD 得到
$$
E = U B V^T
$$

代入就可以得到本质矩阵 E
$$
E = U diag(\theta_1, \theta_2, 0) V^T
$$

### 单应矩阵

单应矩阵反映了两个平面之间的映射关系，若场景中的特征点都落在同一平面上，如墙，地面，可以通过单应性来进行运动估计。这种情况在相机携带的俯视角相机或顶视角相机比较常见

单应矩阵通常描述处于共同平面上的一些点在两张图像之间的变换关系。考虑在图像 $I_1, I_2$ 有一对匹配好的特征点 $p_1, p_2$, 这些特征点落在平面D上，这个平面应该满足：
$$
n^TP + d = 0\\
\\
-\frac {n^TP} d = 1

p_2 = K(RP+t) = K(PR+t(-\frac {n^TP} d)) \\
    = K(R-\frac {n^TP} d)K^{-1}p_1 \\
\\
将中间部分记为H，即为单应矩阵
p_2= Hp_1
$$

当可能存在误匹配的情况时，我们会更倾向于使用随机采样一致性（Random Sample Concensus RANSAC)来求

## 三角测量

在得到运动之后，我们还需要用相机的运动估计特征点的空间位置，在单目SLAM中，无法通过单张图片获得像素的深度信息，我们需要通过三角测量（Triangulation）或三角化的方法来估计地图点的深度
$$
s_1x_1 = s_2Rx_2 + t \\
s_1x_1^\times x_1 = 0 = s_2x_1^ \times Rx_2 + tx_1^\times \\
$$

三角测量是由平移得到的，由平移才会有对极几何中的三角形，才能谈得上三角测量。纯旋转无法使用三角测量，平移较大是，三角测量比较精确，分辨率大精度越高

## 3D-2D：PnP

PnP (Perspective-n-point) 是求解3D到2D点对运动的方法。
它描述了当知道N个3D空间点及其投影位置时，如何估计相机的位姿，

2D-2D的对极几何方法需要8个或8个以上的点对（以八点法为例），且存在初始化，纯旋转和尺度的问题。

如果其中一个图像中一个特征点的3D位置是已知的，那么最少只需要3个点对就可以估计相机运动。

特征点的3D位置可以由三角化或者RGB-D相机的深度图确定。

因此在双目或者RGB-D的视觉里程计中，我们可以直接使用PnP估计相机运动，而在单目相机中，必须先进行初始化，然后才能使用PnP

3D-2D方法不需要使用对极约束，又可以在很少的匹配点中获得较好的运动估计，是最重要的一种位姿估计方法

PnP有很多求解方法，包括：
+ 用3对点估计位资的P3P
+ 直接线性变换（DLT）
+ EPnP（EfficientPnP）
+ UPnP
+ 还有就是构建非线性优化，构建最小二乘问题并迭代求解，也就是万金油的Bundle Adjustment

### 直接线性变换 DLT

考虑某个空间点 P，它的齐次坐标为 $[X, Y, Z, 1]^T$，在第一帧相机成像坐标系下的像素坐标为 $[u_1, v_1, 1]^T$，在第二帧相机成像坐标系下的像素坐标为 $[u_2, v_2, 1]^T$，那么根据针孔相机模型，我们定义增广矩阵$[R \mid t]$ 为一个3x4的矩阵，其中 R 是旋转矩阵，t 是平移向量，那么我们有
$$
s\begin{bmatrix}
u_1 \\
v_1 \\
1
\end{bmatrix} = \begin{bmatrix}
t_1 & t_2 & t_3 & t_4 \\
t_5 & t_6 & t_7 & t_8 \\
t_9 & t_{10} & t_{11} & t_{12}
\end{bmatrix} \begin{bmatrix}
X \\
Y \\
Z \\
1
\end{bmatrix}
$$
用最后一行消去s可得
$$
u_1 = \frac {t_1X+t_2Y+t_3Z+t_4} {t_9X+t_{10}Y+t_{11}Z+t_{12}} \\
v_1 = \frac {t_5X+t_6Y+t_7Z+t_8} {t_9X+t_{10}Y+t_{11}Z+t_{12}}
$$

再简化一下
$$
T_1 = (t_1, t_2, t_3, t_4)^T \\
T_2 = (t_5, t_6, t_7, t_8)^T \\
T_3 = (t_9, t_{10}, t_{11}, t_{12})^T \\
t_1^TP - t_3^TPu_1 = 0 \\
t_2^TP - t_3^TPu_2 = 0
$$

由于t有12维，因此至少需要6对匹配点才可以实现T的线性求解。这种方法称为直接线性变换（DLT）。在实际应用中，我们通常会使用奇异值分解（SVD）来求解T。

但在实际使用中，我们忽略了矩阵参数之间的联系。因为旋转矩阵是一个正交矩阵，所以旋转矩阵的每一列都是单位向量，且它们之间相互正交。因此，我们可以通过约束条件来进一步优化T的求解。

### P3P

P3P是另一种解PnP的方法，它仅使用3对匹配点，对数据的要求较少

+ 它的输入数据为3对3D-2D匹配点，
+ 利用三角相似性约束
  + $OA^2 + OB^2 -2OA*OB*cos<a,b> = AB^2$
  + $OC^2 + OB^2 -2OC*OB*cos<c,b> = CB^2$
  + $OC^2 + OA^2 -2OA*OC*cos<a,c> = AC^2$
+ 将上式同除$OC^2$, 记 $v=\frac {AB^2} {OC^2}, uv=\frac {BC^2} {OC^2}, wv=\frac {AC^2} {OC^2}$

$$
(1-u)y^2 - ux^2 - cos<b,c>y + 2uxycos<a,b> + 1 = 0
(1-w)x^2 - wy^2 - cos<a,c>x + 2wxycos<a,b> + 1 = 0
$$

我们已知三个特征点的位置，2d点的图像位置，三个余铉值，u，w是已知的，方程变成了求x，y的二元二次方程，通过吴消元法可以求解出x，y，然后通过旋转矩阵和平移向量可以求解出相机的位姿

从P3P的原理可以看出，为了求解PnP，利用了三角形相似性质，最后把问题转化成3D到3D的位资估计问题，带有匹配信息的3D-3D位姿求解非常容易，所以这种思路非常有效，其他方法比如EPnP也采用这种思路

+ P3P只利用了3个点的信息，当给定的配对点多于三组时，难以利用更多的信息
+ 如果3D点或2D点受噪音影响，或者存在误匹配，则算法失效

后续还提出了许多别的方法，如EPnP，UPnP等，他们利用更多的信息，而且用迭代的方式对相机位姿进行优化，以尽可能的消除噪音的影响

不过，相对于P3P来说，原理会更加复杂一些，在SLAM中，通常的做法是先使用P3P/EPnP等方法估计相机位姿，然后构建最小二乘优化问题对估计值进行调整 (Bundle Adjustment), 接下来我们将从非线性优化角度来看PnP问题

### Bundle Adjustment

除了使用线性方法外，我们还可以把PnP问题构建成一个定义于李代数上的非线性最小二乘问题

前面的线性方法，往往是先求相机位资，再求空间点位置， 而非线性优化则是把他们都堪称优化变量，放在一起优化。这时一种非常通用的求解方式，

考虑n个三维空间点P以及其投影p，我们希望计算相机的位姿 R，t，它的李代数比啊是为 $\zeta$, 假设空间点的坐标为 $P_i= [X_i, Y_i, Z_i]^T$，其投影的像素位置为 $p_i= [u_i, v_i, 1]^T$，那么我们有
$$
s_i\begin{bmatrix}
u_i \\
v_i \\
1
\end{bmatrix} = K(RP_i + t) = Kexp(\zeta^{\times})\begin{bmatrix}
X_i \\
Y_i \\
Z_i \\
1
\end{bmatrix}
$$

那么他的目标函数就是
$$
\zeta^* = \min_{\zeta} \sum_{i=1}^{n} ||s_i\begin{bmatrix} u_i \\ v_i \\ 1 \end{bmatrix} - Kexp(\zeta^{\times})\begin{bmatrix} X_i \\ Y_i \\ Z_i \\ 1 \end{bmatrix}||^2
$$

这个问题就可用用高斯牛顿法，LM法等算法进行优化求解

## 3D-3D： ICP

最后，我们看一下3D-3D的位姿估计问题，即ICP（Iterative Closest Point）算法

假设我么有一组匹配好的点
$$
P_k = {p_1,p_2, ..., p_n}, P^, = {p_1^,,p_2^,, ..., p_n^,} \\
p_i = Rp_i^, + t
$$

可以注意到，这和相机模型没有任何关系，这种方法广泛应用于激光SLAM中，不过由于激光数据特征不够丰富，我们无法知道两个点集的匹配关系，只能认为距离最近的两个点为同一个，所以这个方法称为迭代最近点

同样的这样也存在两种求解的方法
+ 线性方法 SVD
+ 最小二乘优化 BA

### SVD方法

### 非线性优化方法
