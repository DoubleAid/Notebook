# 11 回环检测

## 主要目标

1. 理解回环检测的必要性
2. 掌握基于词袋的外观式回环检测
3. 通过DBow3的实验，学习词袋模型的实际用途

我们知道SLAM主体（前端和后端）主要的目的在于估计相机运动，而回环检测模块，无论是目标上和方法上，都与前面的内容相差很大

## 回环检测的意义

前端提供特征点的提取和轨迹，地图的初值
后端负责对所有这些数据进行优化

如果像VO 这样仅考虑相邻时间的关联，那么误差将会不断的累积，使得整个SLAM出现累积误差，长期估计将不可靠

回环检测能够给出了相邻帧之外更加久远的约束，例如x_1 到 x_100 之间的位姿变换，当两者经过了同一个地方

如果能够成功检测，就可以为后端的位姿图提供更多的有效数据，从而得到一个全局一致的估计

1. 它关系到我们估计的轨迹和地图在长时间下的正确性
2. 回环检测提供了当前数据与所有历史数据的关联
3. 在跟踪算法丢失后，我们还可以利用回环检测进行重定位

我们有时候把仅有前端和局部后端的系统称为VO，而把带有回环检测和全局后端的系统称为SLAM

## 回环检测的实现

最简单的方法就是对任意两幅图像都作一遍特征匹配，根据正确匹配的数量确定哪两幅图存在关联---这确实是一种朴素且又掉的思想
缺点在于，我们盲目的假设任意两幅图都可能存在回环，使得检测的数量太大了

上面的思路太过粗糙，我们至少希望有一个哪里可能出现回环的预计

+ 第一种：基于里程计的几何关系
+ 第二种：基于外观

基于几何关系就是说，当我们的相机运动到了之前的某个位置附近，检测他们之间有没有回环，这种方法的缺点是，如果相机运动的轨迹比较复杂，那么这种检测的准确性就会降低
而且，由于存在累积误差，往往没法正确的发现运动到了之前的某个位置

第二种是基于外观，他和前后端都无关，根据两幅图的相似性确定回环检测关系，这种方法摆脱了累积误差，使得回环检测模块称为相对独立的模块
那么基于外观的回环检测算法中，核心的问题就变成了如何计算图像间的相似性。直接进行灰度的检测是不行的，无论是角度的转变，光照强度的转变，都会使得灰度值发生变化

### 准确率和召回率

下面是回环检测的结果分类

|算法\事实|是回环|不是回环|
| ----- | ----- | ------ |
| 是回环 | 真阳性 TP | 假阳性 FP |
| 不是回环 |假阴性 FN | 真阴性 TN |

+ 假阳性称为感知偏差，假阴性称为感知编译

为了估算某种特定算法，可以统计在数据集上出现的次数

有两个评价标准：准确率和召回率 （Precision & Recall）

$$
Precision = \frac {TP} {(TP + FP)} \\
Recall = \frac {TP} {TP + FN}
$$

为了评价算法的好坏，我们会测试他在各种配置下的P和R值，然后作出一条P-R曲线

在SLAM中，我们对准确率的要求更高，而对召回率则相对宽容一些

## 词袋模型

为什么不使用特征点来做回环检测呢？我们对两幅图像的特征点进行匹配，只要匹配的数量大于一定的数量，就认为出现了回环。

词袋，也就是Bag-of-Words(BoW), 目的是用“图像上有哪几种特征”来描述一幅图像

1. 确定对图片描述的特征--- 对应Bow的单词，许多单词放在一起，组成了字典
2. 确定一幅图出现了哪些在字典中定义的概念--- 我们用单词出现的情况（或者直方图）描述整幅图像，也就是把一幅图转化成一个向量的描述
3. 比较上一部中描述的相似程度

描述向量只描述了单词的数量，而没有描述单词出现的位置，因此就算相机发生了运动，只要物品出现在视野里，我们就保证描述向量不发生变化

那么两个图片的相似性
$$
s(a, b) = 1 - \frac 1 W ||a - b||_1
$$

其中范数取L1范数，即各个元素绝对值之和

接下来需要解决的问题：

1. 我们虽然清楚了字典的定义方式，但它到底是怎么来的
2. 如果我们能够计算两幅图像的相似程度评分，是否就足够判断回环了吗

## 字典

字典是由很多单词组成，而每个单词代表了一个概念，他应该是图像中某一类特征的组合，所以字典生成问题类似于一个聚类问题

聚类问题在无监督机器学习中特别常见的，让机器自行寻找数据中的规律。Bow字典生成问题也是其中之一

假设我们对大量的图像提取了特征点，比如说N个，现在想找到一个有k个单词的字典，每个单词可以看作局部相邻特征点的几何，

K-means是如何操作的呢

1. 随机选取K个中心点
2. 对每个样本，计算它与每个中心点之间的距离，取最小的最为他的归类
3. 如果每个中心点的变化都很小，即算法收敛，推出，否则按照中心点执行第二步

K-means的做法是朴素且简单有效的，但需要指定巨累数量，随机选取中心点可能导致每次聚类结果都不相同，以及效率上也有一点问题

随后开发了 层次聚类法，K-means++等算法弥补不足

现在的问题变成了如何跟驴图像中某个特征点查找字典中相应的单词

朴素的想法就是，将每一个单词都进行比对，取最相似的那个

但整体数量有点大，不如对单词进行某种排序，例如 Fabmap中的Chou-Liu tree

我么现在使用一种比较简单的数结构来表示

1. 在根结点，用k-means把所有样本聚类成k类，实际上为了保证聚类均匀性会使用k-means++,这样就得到了第一层
2. 对第一层的每个节点，把属于该节点的样本在聚成k类，得到下一层，
3. 以此类推，最后得到叶子层，叶子层就是所谓的words

## 相似度计算

接下来讨论相似度问题，普通的匹配我们对所有的单词都是一视同仁的，但是有些单词可以明显区分，有一些却没什么用，我们希望对单词的区分性
或重要性加以评估，给他们不同的权重来起到更好的效果

在文本检索中，常用的一种做法称为 TF-IDF(Term Frequency-Inverse Document Frequency) 或频率-逆文档频率

TF 的思想是，某个单词在一幅图中经常出现，他的区分度就高，

IDF 的思想是，某个单词在字典中出现的频率越低，则分类图像时区分度越高

在词袋模型中，在建立字典时可以考虑IDF部分，我们统计某个叶子的节点 w_i 中的特征数量和所有特征数量的比例作为IDF
$$
IDF_i = log \frac n n_i
$$

ni表示单词i的特征数量，n表示所有的特征数量

另一方面，TF部分则是指某个特征在单幅图像中出现的频率。假设图像A中单词wi出现了ni次，一共出现的单词次数为 n，那么TF为
$$
TF_i = \frac n_i n
$$

于是，wi 的权重等于 TF乘 IDF之积
$$
\mu = TF_i \times IDF_i
$$

考虑权重只有，对于某幅图，特征点对应到许多单词

可以预测到描述向量会存在大量的0，他是一个稀疏阵

当一些昌吉过度相似时，我们的相似性评分不能够太过绝对，我们希望和前一帧之间的比值这种来体现
$$
s(v_t, v_{tj})^, = s(v_t, v_{tj}) / s(v_t, v_{t-\Delta t})
$$

这样就可以说，如果当前帧和之前的某个关键帧的相似度超过了当前帧和上一个关键帧相似度的3倍，就认为可能存在回环

### 关键帧的处理

在检测回环时，我们必须考虑到关键帧的选取，如果关键帧选的太近，就会导致两个关键帧之间的相似性过高，相比之下不容易检测出历史数据中的回环，所以回环检测的帧最好稀疏一些，彼此不太相同，又能涵盖整个环境

回环检测完全依赖于外观而没有利用任何几何信息，这导致外观相似的图像容易被当成回环，所以在回环检测之后，还有一个验证步骤

验证的方法有很多，
+ 其中一个就是设立回环的缓存机制，认为单次检测到的回环并不足以构成良好的约束，而一段时间内一直检测到的回环，才认为是正确的回环
+ 另一种是空间上的一致性检测，将运动放到位姿图中，检查与之前的估计是否有出入
