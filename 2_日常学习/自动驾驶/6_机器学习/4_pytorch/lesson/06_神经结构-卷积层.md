以 2d卷积 为例, 参考 torch.nn.functional 的 conv2d

`torch.nn.functional.conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1)->Tensor`
+ input: 输入为一个tensor包括(minibatch, in_channels, iH, iW)
+ weight: 权重 或 卷积核
+ bias: 偏置
+ stride: 步幅, 可以是单个数，也可以是一个元祖（H, W）分别指定横向和纵向的步幅
+ padding: 输入图像的上下左右进行填充， 图像变成(H+2padding, W+2padding),填充数字为0 默认不进行填充

```python
import torch
import torch.nn.functional as F

input=torch.tensor([[1,2,0,3,1],
                    [0,1,2,3,1],
                    [1,2,1,0,0],
                    [5,2,3,1,1],
                    [2,1,0,1,1]])

kernel=torch.tensor([[1,2,1],
                     [0,1,0],
                     [2,1,0]])

input=torch.reshape(input, (1,1,5,5))
kernel=torch.reshape(kernel, (1,1,3,3))

print(input.shape)
print(kernel,shape)

output = F.conv2d(input, kernel, stride=1)
```

`torch.nn.conv2d`
+ in_channels (int): 输入的 channel
+ out_channels (int): 多个卷积核得到多个channel
+ kernel_size (int or tuple): 训练的时候会不断调整，
+ stride
+ padding
+ padding_mode
+ dilation: 默认为1, 卷积核各元素点在 输入 上的间隔（空洞卷积）
+ groups
+ bias

实际练习：查看卷积结果
```
import torch
import torchvision
from torch.nn import Conv2d
from torch.utils.data import dataloader
from torch.utils.tensorboard import SummaryWriter

dataset = torchvision.datasets.CIFAR10("../data", train=False, transform=torchvision.transforms.ToTensor(), download=True)

dataload = torch.utils.data.DataLoader(dataset, batch_size=64)

class Test(torch.nn.Module):
  def __init__(self):
    super(Test, self).__init__()
    self.conv1 = Conv2d(in_channels = 3, out_channels=6, kernel_size=3, stride=1, padding=0)

  def forward(self, x):
    return self.conv1(x)

test = Test()

writer = SummaryWriter("../logs")

step = 0
for data in dataload:
  imgs, targets = data
  output = test(imgs)
  print(imgs.shape)
  print(output.shape)
  writer.add_images("input", imgs, step)
  output = torch.reshape(output, (-1, 3, 30, 30))
  writer.add_images("output", output, step)
  step += 1
```

输入和输出的shape关系
+ Input $(N, C_{in}, H_{in}, W_{in})$
+ Output $(N, C_{out}, H_{out}, W_{out})$
  + $H_{out}=[{{H_{in}+2*padding[0]-dilation[0]*(kernel_size[0]-1)-1} \over stride[0]} + 1]$
  + $W_{out}=[{{W_{in}+2*padding[0]-dilation[0]*(kernel_size[0]-1)-1} \over stride[0]} + 1]$