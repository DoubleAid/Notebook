# 视觉回环 回环检测方法

## 粗检测

1. 基于局部特征的词袋模型（BoW）

    + 提取图像局部特征（SIFT，ORB），构建视觉词袋
    + 将当前帧特征转化为词袋向量，与历史帧向量计算相似度，筛选候选回环
    + 再通过几何验证（如 RANSAC + 基础矩阵/单应矩阵）排除误匹配
    + 特点是精度高，鲁棒性强，是视觉SLAM经典方案（如ORB-SLAM）

2. 基于全局图像描述子的方法

    + 直接提取图像全局特征（如 NetVLAD，CosPlace, Scan-Context 视觉版）， 生成固定长度向量
    + 通过向量余弦相似度快速检索候选帧，无需构建词典
    + 特点：速度快，适合实时场景

3. 基于深度学习的端到端方案

    + 利用transformer（如 Siamese 网络、孪生网络）直接学习图像相似度；
    + 输入当前帧与历史帧图像，模型输出是否为回环的概率；
    + 特点：适配复杂动态场景，对光照、视角变化鲁棒性强，但依赖大量标注数据。

## 精检测部分

1. 几何约束验证（局部特征法）

    + 通过候选帧和当前帧的匹配特征点，用 RANSAC 求解基础矩阵/单应性矩阵，过滤外电
    + 验证极线约束或重投影误差

2. 深度学习提高置信度阈值

## 验证检查

1. 时空一致性检验：要求连续2-3帧军检测到同一候选回环，且满足时空约束，避免单帧误匹配
2. 位姿图一致性校验：将回环约束（如基础矩阵推导的相对位姿）加入位姿图优化，若优化后全局残差收敛且无显著抖动，则确认有效回环
3. 重投影误差全局校验：用回环约束优化后的位姿，将当前帧特征点重投影到候选帧，要求平均重投影误差 < 阈值，且分布均匀
3. 场景一致性验证：对比候选帧与当前帧的语义特征(如车道线，建筑物轮廓)，若语义类别分布差异过大，则判定为误匹配