# 卡尔曼滤波及其扩展

滤波器方法用来在存在不确定信息的情况下，​估计一个动态系统的内部状态​

## <font color="skyblue">卡尔曼滤波 KF</font>

卡尔曼滤波认为 当前的状态只和前一帧相关，且当前状态和上一帧的状态存在线性关系，如 当前位置 = 前一帧位置 + 速度 x 时间间隔

### <font color="YellowGreen">状态方程</font>

$$
x_k = A_kx_{k-1} + B_ku_k + w_k \\
z_k = C_kx_k + v_k \\
$$

### <font color="YellowGreen">卡尔曼滤波的五个公式</font>

#### <font color="Coral">1. 预测</font>

$$
E_{先验} = A_kE_{k-1}^{后验} + B_ku_k \\
D_{先验} = A_kD^{后验}_{k-1}A_k^T + Q_k \\
$$

#### <font color="Coral">2. 更新</font>

$$
取 K = D_{先验}C_k^T(C_kD_{先验}C_k^T + R)^{-1} = \frac {D_{先验}C_k^T} {C_kD_{先验}C_k^T + R} \\
E_{后验} = E_{先验} + K(z_k - C_kE_{先验}) \\
D_{后验} = (I - K C_k)D_{先验} = D_{先验} - K C_kD_{先验}
$$

#### <font color="Coral">Q 和 R 的理解</font>

+ Q 表示运动模型的不确定性，Q越小，表示运动模型越稳定，不会产生突然的不符合函数的运动变化
+ R 表示观测模型的不确定性，R约小，表示观测模型越稳定，不会产生突然的观测错误

## <font color="Skyblue">扩展卡尔曼滤波 EKF</font>

问题: 机器人的运动涉及角度和旋转，这些都是非线性的

核心问题：标准卡尔曼滤波里的矩阵乘法（如 A * x）无法描述这些复杂的非线性关系。如果我们强行用线性模型去近似非线性系统，误差会非常大，导致滤波结果发散（完全不准）。

扩展卡尔曼滤波​ 就是为了解决非线性问题而生的。它的核心思想非常直观：
如果系统是非线性的，我们就在当前的最佳估计点附近，用切线（线性）来近似这个曲线（非线性）。也就是一阶泰勒展开，也就是雅可比矩阵

### <font color="YellowGreen">状态方程</font>

$$
x_k = f(x_{k-1}, u_k, w_k)
$$

+ $x_k$: k时刻的系统状态（我们想要估计的量）。
+ $f$: 非线性的状态转移函数。
+ $u_k$: k时刻的控制输入（已知量）。
+ $w_k$: k时刻的过程噪声，假设为高斯白噪声，$w_k∼N(0,Q_k)$

$$
z_k = h(x_k, v_k)
$$

+ $z_k$： k时刻的测量值。
+ $h$： 非线性的观测函数。
+ $v_k$： k时刻的观测噪声，假设为高斯白噪声，$v_k∼N(0,R_k)$
+ 假设 $w_k$ 和 $v_k$ 相互独立。

由于 f和 h是非线性的，状态和噪声的分布不再是高斯的，并且我们无法像标准KF那样简单地用矩阵传播均值和协方差。

### <font color="YellowGreen">扩展卡尔曼滤波的公式推导</font>

我们无法直接计算状态的期望值 $E[f(x_{k−1},u_k,w_k)]$。EKF采取一个简单直接的近似：忽略过程噪声的非线性效应，并围绕最大概率点（即上一时刻的后验估计）进行线性化。

首先将非线性函数 f 在 $x_{k-1}$ 处进行一阶泰勒展开：

$$
x_k \approx f(E_{k-1}^{后验}, u_k, 0) + F_k(x_k-E^{后验}_{k-1}) + w_k
$$

+ $F_k$ 是 f对状态 x 的雅可比矩阵在 $(E_{k-1}^{后验}, u_k , 0) 处的值
$
F_k = \frac {\partial f} {\partial x} |_{E_{k-1}^{后验}, u_k}
$

令 x = x_{k-1}

$$
z_k \approx h(x_{k}^{先验}, 0) + H_k(x_k - x_{k}^{先验}) + v_k
$$

### <font color="YellowGreen">扩展卡尔曼滤波的五个公式</font>

我们使用下面这些符号统一表示

$$
\widehat{x}_{k} = E_{k}^{后验} = 后验的均值 \\
\widehat{P}_{k} = D_{k}^{后验} = 后验的方差 \\
\overline{x}_{k} = E_{k}^{先验} = 先验的均值 \\
\overline{P}_{k} = D_{k}^{先验} = 先验的方差
$$

那么公式表示成以下形式

#### <font color="Coral">预测</font>

$$
\overline{x}_{k} = f(\widehat{x}_{k-1}, u_k) \\
\overline{P}_{k} = F\widehat{P}_{k-1}F^T + R
$$

#### <font color="Coral">更新</font>

更新卡尔曼增益 K

$$
K = \overline{P}_{k}H^T(H\overline{P}_{k}H^T + Q) = \frac {\overline{P}_{k}H^T} {H\overline{P}_{k}H^T + Q}
$$

更新后验概率分布

$$
\widehat{x}_k = \overline{x}_k + K(z_k - H\overline{x}_k) \\
\widehat{x}_k = \overline{P}_k - KH\overline{P}_k
$$

这里的 F 和 H 分别是 f 和 h 在 x = $\widehat{x}_{k-1}$ 和 x = \overline{x}_{k} 处的导数

## <font color="skyblue">误差状态卡尔曼滤波 ESKF</font>

ESKF整体流程如下：当IMU测量数据到达时，我们把它积分后，放入名义状态变量中。由于这种做法没有考虑噪声，其结果自然会快速漂移，于是我们希望把误差部分作为误差变量，放在ESKF中。ESKF内部会考虑各种噪声和零偏的影响，并且给出误差状态的一个高斯分布描述。同时，ESKF本身作为一种卡尔曼滤波器，也具有预测过程和修正过程，其中修正过程需要依赖IMU以外的传感器观测。当然，在修正之后，ESKF可以给出后验的误差高斯分布，随后我们可以把这部分误差放入名义状态变量中，并把ESKF置零，这样就完成了一次循环。

### <font color="YellowGreen">误差状态卡尔曼滤的公式推导</font>

$$
\dot{x}_t = f(x_t, u, w)
$$

名义状态忽略了误差值，会导致迅速发生飘移

$$
\dot{x} = f(x, u, 0)
$$

那么可以得到误差状态的表达式

$$
\dot{x}_t = \dot{x} \oplus \delta{\dot{x}} \approx f(x, u, 0) +  \frac {\partial{f}} {\partial{\delta{x}}} \delta{x} + \frac {\partial{f}} {\partial{w}}w
$$

所以线性化的误差状态方程

$$
\delta{\dot{x}} = F\delta{x} + Gw
$$

其中：

+ $F = \frac {\partial{f}} {\partial{\delta{x}}}|_x$ 是误差状态转移矩阵的雅可比矩阵
+ $G = \frac {\partial{f}} {\partial{w}}|_x$
+ 由于 $\delta{X}$ 很小，这个线性模型是高度精确的

### <font color="YellowGreen">误差状态卡尔曼滤波的五个公式</font>

#### <font color="Coral">预测</font>

$$
\overline{x}_k = f(\widehat{x}_{k-1}, u_{k-1}, 0)
$$

通过积分非线性的名义状态模型进行

$$
\overline{P}_k = F\overline{P}_{k-1}F^T + GQG^T
$$

#### <font color="Coral">更新</font>

首先计算卡尔曼增益

$$
K = \overline{P}_kH^T(H\overline{P}_kH^T + R)^{-1}
$$

同样的，这里的 H = $\frac {\partial{h}} {\partial \delta{x}}|_x$
它描述了误差状态如何影响观测残差

$$
\delta{x}_k = K{z_k - h{\overline{x}_k}}
$$

注入重置 (injection & reset)

+ 注入：将估计出的误差状态注入到名义状态中，以修正名义状态 $x_k \leftarrow x_k \oplus \delta x_k$, 经过这一步，名义状态得到了修正，变得更接近真实状态
+ 重置：将误差状态置为0， 并更新其协方差矩阵

$$
\delta x_k \leftarrow 0 \\
\widehat{P}_k \leftarrow J\widehat{P}_kJ^T
$$

其中 J 是重置操作的雅可比矩阵: $J = \frac {\partial{x_{new}}} {\partial{\delta{x_{old}}}}$

+ 当 $\oplus$ 是普通加法时，J = I
+ 但对于朝向等状态，J不是单位阵，需要特殊处理以保持协方差的正确性

## <font color="skyblue">无迹卡尔曼滤波 UKF</font>

核心思想：
EKF 的弱点在于它对非线性函数进行一阶线性化近似。UKF 采用了一种完全不同的思路：

**
与其对复杂的非线性函数进行线性化，不如我们直接去近似这个非线性函数变换后的概率分布。
**

UKF 认为，逼近一个概率分布比逼近一个任意的非线性函数要更容易。
那么，如何近似概率分布呢？UKF 使用了一种叫做 无迹变换（Unscented Transform, UT）​ 的巧妙方法。

### <font color="YellowGreen">无迹变换</font>

无迹变换的核心思想是：

1. **选择一组特定的样本点（称为 Sigma 点）**：这些点并不是随机采样的，而是根据当前状态（均值 x和协方差 P）确定性地选取的。这些 Sigma 点能够完全捕获状态的均值和协方差信息（直到二阶）。
2. **通过非线性函数传播每个 Sigma 点**：将每个 Sigma 点代入非线性函数 f或 h，得到一组变换后的点。这个过程是精确的，没有进行任何线性化。
3. **计算变换后点的统计量**：对变换后的这组点计算其均值和协方差，这个新的均值和协方差就是非线性变换后状态的概率分布的近似。

#### <font color="Coral">为什么叫“无迹”（Unscented）？</font>

有一种解释是，与像粒子滤波那样随机采样大量粒子（留下“痕迹”）不同，UKF 只使用少量确定性选择的点，可以说是“无迹”可寻。这个名字更多是为了区别于其他方法。

#### <font color="Coral">Sigma 点选取策略</font>

对于一个 n维状态向量，通常选取 2n+1个 Sigma 点。这些点关于均值对称分布。

给定当前状态估计 $\widehat{x}_{k-1}$ 和 协方差 $\widehat{P}_{k-1}$, sigma 点集按照如下方式选取：

$$
\mathcal{X}_0 = \widehat{x}_{k-1} \\
\mathcal{X}_i = \widehat{x}_{k-1} + \sqrt{n + \lambda} (\sqrt{\widehat{P}_{k-1}})_{i}, i = 1 ... n \\
\mathcal{X}_i = \widehat{x}_{k-1} - \sqrt{n + \lambda} (\sqrt{\widehat{P}_{k-1}})_{i-n}, i = n+1, ..., 2n
$$

其中

+ $\lambda = \alpha^2(n + k) - n$ 是一个缩放参数
+ $\alpha$ 决定 Sigma 点的分布范围（通常是一个小正数，如 1e−3）
+ k 是一个次要缩放参数，通常设为 0或 3−n。
+ $\sqrt{P}$ 是矩阵平方根（通常通过乔里斯基分解计算）$(\sqrt{P})_i$ 表示矩阵的第 i列。

每个 Sigma 点都有两个权重：

+ 均值权重 $W_m^{(i)}​：用于计算变换后的均值。
+ 协方差权重 $W_c^{(i)}：用于计算变换后的协方差。

### <font color="YellowGreen">无迹卡尔曼滤波的算法步骤</font>

#### <font color="Coral">预测步骤</font>

1. **生成 Sigma 点**：基于上一时刻的后验估计 $\widehat{x}_{k-1}, \widehat{P}_{k-1}$, 按照上面的规则生成 $\mathcal{X}_{k-1}^{(i)}$

2. **通过过程模型转播Sigma点**：将每个 Sigma 点通过非线性的过程模型 f(⋅)​ 传播

    $$
    \overline{\mathcal{X}}_{k}^{(i)} = f(\mathcal{X}_{k-1}^{(i)}, u_{k-1})
    $$
    注意：这里没有雅可比矩阵，是直接计算非线性函数。

3. **计算预测的先验均值和协方差**：对传播后的 Sigma 点集进行加权平均。

$$
\overline{x}_k = \sum_{i=0}^{2n}W_m^{(i)}\mathcal{\overline{X}}_k^{(i)} \\
\overline{P}_k = \sum_{i=0}^{2n}W_c^{i}[\mathcal{\overline{X}}_k^{(i)} - \overline{x}_k][\mathcal{\overline{X}}_k^{(i)} - \overline{x}_k]^T + Q
$$

其中 Q是过程噪声协方差

#### <font color="Coral">更新步骤</font>

1. **生成观测 Sigma 点**：基于上一时刻的后验估计 $\widehat{x}_{k-1}, \widehat{P}_{k-1}$, 按照上面的规则生成 $\mathcal{X}_{k-1}^{(i)}$（或者直接复用预测步骤中的点）
2. **通过观测模型传播 Sigma 点**：将每个 Sigma 点通过非线性的观测模型 h(⋅)​ 传播，得到预测的观测值。
    $$
    \mathcal{Z}_k^{(i)} = h(\overline{\mathcal{X}}_{k}^{(i)})
    $$
3. **计算预测观测的均值和协方差**：
    $$
    \widehat{z}_k = \sum_{i=0}^{2n}W_m^{(i)}\mathcal{Z}_k^{(i)} \\
    P_z = \sum_{i=0}^{2n}W_c^{(i)}[\mathcal{Z}_k^{(i)} - \widehat{z}_k][\mathcal{Z}_k^{(i)} - \widehat{z}_k]^T + R
    $$
4. **计算状态与观测的互协方差**:
    $$
    P_{xz} = \sum_{i=0}^{2n}W_c^{(i)}[\mathcal{\overline{X}}_k^{(i)} - \overline{x}_k][\mathcal{Z}_k^{(i)} - \widehat{z}_k]^T
    $$
5. 标准卡尔曼更新
    + 计算卡尔曼增益：$K = P_{xz}P_z^{-1}$
    + 状态更新: $\widehat{x}_k = \overline{x}_k + K(z_k - \widehat{z}_k)$
    + 协方差更新：$\widehat{P}_k = \overline{P}_k - KP_zK^T$

### <font color="YellowGreen">总结</font>

+ UKF 的优势在于其无需计算雅可比矩阵，实现方便，且精度通常优于 EKF，能达到二阶精度。它用一种更“直接”的方式处理非线性问题。
+ UKF 的代价是计算量稍大（需要多次计算非线性函数），但对于现代计算机，对于状态维度不是特别高（例如 n < 20）的问题，这个代价通常是可接受的。

简单比喻：
+ EKF：像是一个地图绘制员，在当前位置画一条直线（切线）来近似弯曲的道路。
+ UKF：像是一个侦察兵，先派几个探子（Sigma点）到前方道路的关键点去实地探查，然后回来报告整条路的情况（均值和协方差）。虽然派出探子费点事，但得到的地图远比画直线要准确。