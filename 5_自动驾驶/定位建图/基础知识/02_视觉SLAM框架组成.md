# 视觉 SLAM 框架的组成

## 主要目标

1. 理解一个视觉SLAM框架由哪几个模块组成，各个模块的任务是什么

## 引导

+ 一个机器人如果能够自动的探索周围的环境，需要定位（在什么地方）和 建图（周围的环境）

通常情况下通过传感器来感知外界的环境

+ 自身身上的传感器：摄像头，轮式编码器， 激光传感器等
+ 环境中的传感器：导轨，二维码标志

## 视觉SLAM的设备

### 单目相机 Monocular

单目相机就是只使用一个摄像头进行SLAM的做法，叫做单目SLAM （Monocular SLAM）
照片是场景在相机平面留下的投影， 丢失了深度，想要回复三维结构必须改变相机的视角，通过物体在图像上的运动形成的视差进行深度判断
且单目像机不能测量物体实际的大小，丢失了尺度

优点：

+ 结构简单，成本低

缺点：

+ 需要平移才能计算深度
+ 无法确定真实的尺度

### 双目相机 Stereo

双目相机和深度相机解决的问题就是通过某种方法获取测量物体和相机之间的距离，克服单目像机无法知道距离的缺点

双目相机有两个摄像头组成，两个相机之间的距离成为基线 baseline，通过基线来估计每个像素的空间位置

优点：

+ 能够确定深度，确定真实的尺度

缺点：

+ 结构复杂，需要消耗大量的计算资源，需要使用GPU和FPGA加速
+ 深度量程和精度受双目的基线和分辨率所限

### 深度相机 RGB-D

即配有红外光接收器活激光雷达的相机，通过返回光的时间精确计算物品的距离

常见的RGB-D相机包括 Kinect/Kinect V2、 Xtion Pro Live、RealSense

优点：

+ 确定深度和尺度精确，计算量少

缺点：

+ 测量范围窄，噪音大，视野小，易受日光干扰，无法测量透射材质，主要用于室内

### 全景相机，Event 相机

## 经典视觉SLAM框架

```
传感器数据 --> 前段视觉里程计 --> 后段非线性优化 --> 建图
         ----> 回环检测 ----->
```

整个视觉SLAM流程包括以下步骤

1. 传感器信息读取。在视觉SLAM中主要为相机图像信息的读取和预处理，如果是在机器人中，还可能有码盘，惯性传感器等信息的读取和同步
2. 视觉里程计（Visual Odometry VO）视觉里程计的任务是估算相邻图像间相机的运动，以及局部地图的样子，VO又称为前端 （Front End）
3. 后端优化 （Optimization）。后段接受不同时刻视觉里程计测量的相机位姿，以及回环检测的信息，对他们进行优化，得到全局一致的轨迹和地图，后端优化又称为后端（Back End）
4. 回环检测 （Loop Closing）回环检测判断机器人是否到达过先前的位置，如果检测到回环，他会把信息提供给后段进行处理
5. 建图（Mapping）它根据估计的轨迹，建立与任务要求对应的地图

### 视觉里程计

视觉里程计关心的是相邻图像之间的相机运动，最简单的情况就是两张图像之间的运动关系

为了定量的估计相机运动，必须先了解相机与空间点的几何关系

现在只需要知道，VO能够通过相邻帧间的图像估计相机运动，并恢复场景的空间结构

有了一个视觉里程计，就可以估计两张图像间的相机运动，从而可以估计相机的轨迹 ----> 解决了定位问题
根据每个时刻相机的位置，计算出各个像素在空间中的位置，从而得到了地图 ----> 解决了建图问题

视觉里程计是SLAM 的关键，

**问题**

+ 但仅通过视觉里程计来估计轨迹，将不可避免的出现累积漂移（Accumulating Drift）。这是由于视觉里程计（在最简单的情况下）只估计两个图像间的运动造成的。每一次的误差的积累，会导致一段时间后估计的轨迹不在准确，这就是所谓的漂移
+ 漂移导致无法建立一致的地图，为了解决这个问题，才有了后端优化和回环检测。
  + 回环检测负责把机器人回到原始位置的事情检测出来
  + 后端优化根据回环信息，较正正个轨迹的形状

### 后端优化

后端优化主要是指处理SLAM过程中的噪音，

+ 再精确的传感器也有一定的噪音，除了解决“如何从图像估计出相机运动”之外，还要关心这个估计带有多大的噪音，这个噪音是如何从上一个时刻传递到下一个时刻的，
+ 我们又对这个估计有多大的自信，

后端优化要考虑的问题就是如何从这些带有噪音的数据中估计整个系统的状态，以及这个状态估计的不确定性有多大----这称为最大后验概率估计（Maximum a Posteriori，MAP）

这个状态即包括机器人自身的估计，也包含地图

前端提供待优化的数据以及这些数据的初始值 --> 与计算机视觉领域相关，更关心图像的特征提取和匹配，
后端负责整体的优化过程，不关系数据的来源 --> 主要是滤波和非线性优化算法

SLAM 问题的本质： 对运动主体自身和周围环境空间不确定性的估计，以及如何利用这些不确定性进行建图和定位

为了解决SLAM 问题，我们需要状态估计理论，把定位和建图的不确定性表达出来，然后采用滤波器或非线性优化，估计状态的均值和不确定性（方差）

### 回环检测

回环检测 （Loop Closure Detection）主要解决位置估计随时间漂移的问题

通过某种手段告知机器人回到了原点

+ 环境中的传感器：二维码等
+ 通过对比图片的相似性

如果回环检测成功，可以显著的减小累积误差。视觉回环检测实质上是一种计算图像数据相似性的算法，

在检测到回环之后，我们会把 `A与B是同一个点` 这个信息告诉后端优化，后端根据这些新的信息，把轨迹和地图调整到符合回环检测结果的样子

### 建图

建图是指构建地图的过程，地图大体上分为 度量地图和拓扑地图

+ 度量地图：度量地图强调精确的标识地图中物体的位置关系，通常用疏密（Soarse）和稠密（Dense）
  + 稀疏地图进行一定程度的抽象，只选择一部分有代表意义的东西，称之为路标，不是路标的部分可以忽略掉，对于定位来说，稀疏地图就足够了
  + 稠密地图通常按照某种分辨率，由许多小块组成，
+ 拓扑地图：强调地图元素之间的关系，拓扑地图是一个图

### SLAM问题的数据表达

在离散时间内 t = 1，2，3 ... k
用x表示机器人的位置，某一时刻的位置为 x_t
地图上有许多标识点，用y表示，共有N个，每个时刻，传感器会测量一部分标识点 y_1, y_2, ... y_N

需要对下面两个事情进行描述

+ 运动: 考虑从k-1时刻到k时刻，机器人的位置如何变化
+ 观测: 假设机器人在x_k处探测到了路标y_j, 如何用语言表达出来呢

先从运动上来看，机器人会携带一个测量自身运动的传感器，比如说码盘或惯性传感器，
传感器有一定的运动读数，如加速度，角速度等，无论什么传感器，都可以用一个通用的抽象的数学模型表示

$$
x_k = f(x_{k-1}, u_k, w_k)
$$

其中 $u_k$ 是运动传感器的读数，%w_k% 为噪音

与运动方程相对应的，还有一个观测方程，即当机器人在 $x_k$ 位置时，观测到路标 $y_j$，产生了一个观测数据 $z_{k, j}$。同样用一个抽象函数h来描述

$$
z_{k, j} = h(y_j, x_k, v_{k, j})
$$

其中 $v_{k,j}$ 是这次观测里的噪音

在二位平面上，机器人的位姿可以有两个位置和一个转角来描述，即 $x_k = (x, y, \theta)$
同时传感器也可以测量到机器人在任意两个时间间隔位置和转角的变化量 $u_k = (\Delta x, \Delta y, \Delta \theta)$
如果在某一时刻传感器检测到了一个标识点，且能够测量到两个量即距离r和夹角 $\alpha$，记标识点在空间中位置
$y = [p_x, p_y]$
那么观测方程就可以具体化为

$$
[x, y, \theta]_k = [x, y, \theta]_{k-1} + [\Delta x, \Delta y, \Delta \theta]_k + w_k
$$

$$
[r, \alpha]_{k, j} = [\sqrt{(x - p_x)^2 + (y - p_y)^2}, \arctan\frac{y - p_y}{x - p_x}] + v_{k, j}
$$

这两个方程描述了最基本的SLAM问题：当知道运动测量的读数 u 以及传感器的读数 z， 如何求解定位问题 （估计x）和建图问题 （估计z）？这是SLAM问题建模成了一个状态估计问题：如何通过带有噪音的测量数据，估计内部的，隐藏着的状态变量

状态估计问题的求解，与两个方程的具体形式以及噪音服从哪种分布有关，

按照运动和观测方程是否为线性，噪音是否服从高斯分布进行分类，分为线性/非线性，高斯/非高斯系统

+ 其中 线性高斯最简单，他的无偏的最优估计可以由卡尔曼滤波器（Kalman Filter，KF）给出
+ 非线性非高斯复杂，使用扩展卡尔曼滤波器（Extended Kalman Filter， EKF）和 非线性优化两大类方法去求解
+ 为了克服EKF的缺点，如线性化误差和噪音高斯分布假设，人们开始使用粒子滤波器（Particle Filter）等其他滤波器
+ 时至今日，主要是用图优化来进行状态估计

