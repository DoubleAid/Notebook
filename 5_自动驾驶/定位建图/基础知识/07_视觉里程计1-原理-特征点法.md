# 视觉里程计 1

## 主要目标

1. 理解图像特征点的意义，掌握单幅图像中提取特征点及多幅图像中匹配特征点的方法

## 特征点法

视觉SLAM主要分为视觉前端和优化后端，前端也称为视觉里程计（VO）。它的主要功能是根据相邻图像的信息估计出粗略的相机运动，给后端提供较好的初始值。

VO的实现方法，按照是否需要提取特征，分为特征点法的前端以及不提特征的直接法前端。基于特征法的前端是视觉里程计的主流方法。它运行稳定，对光照，动态物体不敏感。

提取，匹配图像特征点 --> 估计两帧之间的相机运动和场景结构

### 特征点

特征点就是图像中一些特别的地方，如角点，边缘，区块

识别的困难度 角点 < 边缘 < 区块

但是角点在移动或旋转后不容易辨别，为此设计出许多更加稳定的局部图像特征

+ SIFT
+ SURF
+ ORB

相比于朴素的角点，人工设计的特征点拥有如下性质

1. 可重复性：相同的区域可以在不同的图像中找到
2. 可区别性：不同的区域有不同的表达
3. 高效率：在同一图像中，特征点的数量应远小于像素的数量
4. 本地性：特征仅与一小片图像区域相关

特征点有 关键点 (key-point) 和描述子 (descriptor) 两部分组成
比如在谈论SIFT特征时，是指“提取SIFT关键点，并计算SIFT描述子”这两件事

+ 关键点是指该特征点在图像里的位置，有一些特征点还具有朝向，大小等信息
+ 描述子通常是一个向量，按照某种认为设计的方式，描述了该关键点周围像素的信息

描述子是按照 “外观相似的特征该有相似的描述子” 的原则设计，因此只要两个特征点的描述子在向量空间上的距离相近，就可以认为它们是同样的特征点

+ SIFT（尺度不变特征变换， Scale-Invariant Feature Transform）是最经典的一种，他充分考虑了光照，尺度，旋转等变化，但是计算量极大
+ FAST 考虑适当降低精度和健壮性，FAST关键点属于计算特别快的一种特征点（没有描述子）
+ ORB (Oriented FAST and Rotated BRIEF) 特征则是目前看来非常具有代表性的实时图像特征。它改进了FAST检测子不具有方向性的问题，并采用速度极快的二进制描述子BRIEF，使整个图像特征提取的环节大大加速

提取过程具有很好的并行性，可以通过GPU等设备来加速计算

### ORB特征

ORB 特征保持了特征子具有旋转，尺度不变形的同时，速度方面提升明显

ORB 也是由 关键点和描述子 两部分组成，他的关键点称为 "Oriented Fast", 是一种改进的FAST角点，
他的描述子称为 BRIEF (Binary Robust Independent Elementary Feature)
提取ORB特征分为如下步骤：

1. FAST 角点提取：找到图像中的"角点"。相较于原版的FAST，ORB中计算了特征点的主方向，为后续的BRIEF描述子增加了旋转不变特性
2. BRIEF描述子：对前一步提取出特征点的周围图像区域进行描述

接下来分别介绍 FAST 和 BRIEF

#### FAST 关键点

FAST是一种角点，主要检测局部像素灰度变化明显的地方，以速度快著称。它的思想是： 如果一个像素与相邻的像素差别过大（过亮或者过暗），那么他可能是角点

1. 在图像中选取像素p，假设它的亮度是 $l_p$
2. 设置一个阈值T，（比如，$l_p$ 的20%）
3. 以像素p为中心，选取半径为3的圆上的16个像素点
4. 加入选取的圆上有连续的N个点大于 $l_p + T$ 或 小于$l_p - T$, 那么像素p可以被认为是特征点 (N 通常是 12， 即 FAST-12。 其他常用的N取值为9和11，分别称为 FAST-9 和 FAST-11)
5. 循环以上四步，对每一个像素执行相同的操作

在FAST-12算法中，为了更高效，可以添加一项预测试操作，以快速排除绝大多数不是角点的像素。具体操作是对于每一个像素，直接检测邻域圆上的第1，5， 9， 13个像素的亮度，只有这4个像素中有三个同时满足条件时，当前像素才可能是一个角点，这样可以大大加速角点检测

+ 原始的FAST角点经常出现扎堆的现象，所以在第一次检测之后，还需要用非极大值抑制   (Non-maximal suppression), 在一定区域内仅保留响应极大值的角点，避免角点集中的问题
  + 按照置信度排序，置信度可以按照中心像素和周围16像素点的亮度差的绝对值
  + 选择置信度最高的点作为最优值
  + 计算重叠度
  + 移除重叠框中置信度较低的点
+ FAST特征点数量很大且不确定，而我们往往希望对图像提取固定数量的特征。我们可以指定最终要提取的角点数量N，对原始FAST角点分别计算Harris响应值，然后选取前N个具有最大响应值的角点作为最终的角点集合
+ FAST角点不具有方向信息。而且它固定取半径为3的圆，存在尺度问题：远看是角点的地方，接近后就不是角点了
  + 尺度不变形由构建图像金字塔，并在金字塔的每一层上检测角点来实现
  + 而特征的旋转是由灰度质心法实现的

通过上述方法，FAST焦点便具有了尺度和旋转的描述，从而大大提升了其在不同图像之间表述的健壮性

#### BRIEF 描述子

BRIEF是一种二进制描述子，其描述向量由许多0和1组成，这里的0和1编码了关键点附近两个像素p和q的大小关系：p大于q就选择0，否则就选择1，选取方法是按照概率分布随机选取

#### 特征匹配

特征匹配解决了SLAM中的数据关联问题 (data association)，即确定当前看到的路标和之前看到的路标之间的对应关系

通过图像和图像或者图像和地图之间的描述子进行准确匹配，可以为后续的姿态估计、优化等操作减轻大量负担。

但图像特征的局部特性，误匹配的情况广泛存在，而且长期以来没有得到有效的解决，部分场景经常出现大量重复的纹理，使得特征描述非常相似

但我们先考虑正确匹配的情况，最简单的方法就是暴力匹配法，即将当前帧的一个特征点和前一帧的所有特征点计算描述子的距离，在BRIEF中使用汉明距离，就是二进制不同位的个数

### SIFT 特征点（Scale-Invariant Feature Transform）

SIFT 需构建多尺度 DoG 金字塔，SURF 虽优化但仍需积分图计算，MSER 需多阈值分割，均不适合实时场景，更适合离线处理。

SIFT 的尺度处理可以理解为：先通过高斯模糊 “模拟不同感知尺度”，再通过下采样 “压缩图像尺寸以降低计算量”，最终在多尺度的差分图像（DoG）中找到跨尺度稳定的极值点，这也是它能实现 “尺度不变性” 的核心原因。

+ 第一步：跨尺度找 “局部极值点”
  + SIFT 会将每个尺度层的图像与相邻尺度层（同尺寸的前后模糊图像、上下尺寸的对应模糊图像）对比。
  + 只有当一个点在 “自身尺度层 + 上下两个相邻尺度层” 的 3×3×3 邻域内，灰度值是唯一的极大值或极小值时，才会被选为 “候选特征点”。
  + 这一步就是你理解的 “跨尺度都是候选点”，核心是确保特征点在不同尺度下都能稳定存在，避免因尺度变化导致特征消失。
+ 第二步：筛选 “稳定点”
  + 候选点中包含大量低对比度点（如平坦区域的噪声点）和边缘点（非稳定特征），需要进一步剔除。
  + 低对比度筛选：通过拟合三维二次函数计算候选点的对比度，低于阈值的直接丢弃。
  + 边缘点筛选：利用 Hessian 矩阵的特征值判断，若特征值差异过大（说明是边缘方向的点），则剔除，只保留真正的角点类稳定特征。

### 特征点方法的对比

