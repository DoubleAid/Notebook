# SVD 求解

## 1. 核心概念：什么是 SVD？

首先，我们需要理解 SVD 本身是什么。对于任意一个形状为 m x n的实数矩阵 A，它的奇异值分解可以表示为：
A = UΣVᵀ
其中：

+ U​ 是一个 m x m的正交矩阵（其列向量是正交的单位向量）。它的列称为 左奇异向量。
+ Σ​ 是一个 m x n的对角矩阵（除了主对角线外，其他元素全为0）。对角线上的非负值称为 奇异值（Singular Values），通常按从大到小排列：σ₁ ≥ σ₂ ≥ ... ≥ σᵣ > 0，其中 r是矩阵 A​ 的秩。
+ Vᵀ​ 是 V​ 的转置，V​ 是一个 n x n的正交矩阵。它的列称为 右奇异向量。
你可以把 SVD 理解为从一个新的、“最优”的正交坐标系（由 U 和 V 的列向量构成）来重新描述矩阵 A​ 的变换过程。

## 2. “SVD 求解”主要解决什么问题？

SVD 之所以强大，是因为它能以一种优雅的方式处理各种“不好解”的线性代数问题。最常见的应用场景包括：

### 场景一：求解线性方程组 Ax = b

这是最直接的“求解”含义。

#### 情况 A：方程有唯一解（A 是满秩方阵）

如果 A​ 是一个可逆的方阵，那么直接使用 x = A⁻¹b即可。而 SVD 提供了一种计算逆矩阵的方法：A⁻¹ = VΣ⁻¹Uᵀ。虽然计算量更大，但数值稳定性极高。

#### 情况 B：方程无解（超定方程组 / 最小二乘问题）

这是最常见的情况。当方程数量多于未知数（m > n），且没有精确解能同时满足所有方程时，我们通常寻找一个 x，使得误差 ||Ax - b||²最小化。这就是线性最小二乘问题。

#### SVD 提供了这个问题的通解：

对 A​ 进行 SVD 分解：A = UΣVᵀ
计算 x​ 的解为：x = VΣ⁺Uᵀb
这里的 Σ⁺是 Σ​ 的伪逆（Pseudoinverse）。对于对角矩阵 Σ，伪逆 Σ⁺的构造方法是：
取 Σ​ 的非零奇异值的倒数（1/σ_i）。
将这些倒数放回一个对角矩阵中，保持原有的行列结构。
如果某个奇异值为 0（或接近于机器精度的极小值，视为数值零），则在伪逆中对应位置设为 0，以避免除以零的错误。
为什么这样能给出最小二乘解？
SVD 自动地将问题投影到由 A​ 的列空间张成的子空间上，并忽略了那些对应于零奇异值的方向（这些方向是引起矛盾和无解的根源），从而得到了最优的近似解。这个方法也被称为 SVD 最小二乘法。
情况 C：方程有无穷多解（欠定方程组 / 最小范数解）
当未知数多于方程（m < n），且 A​ 是满行秩时，存在无穷多个解。在这些解中，我们通常希望找到那个 欧几里得范数（长度）最小的解，即 min ||x|| s.t. Ax = b。
SVD 同样给出了这个解：
使用相同的公式 x = VΣ⁺Uᵀb。
在这种情况下，伪逆 Σ⁺会自动将解投影到由 A​ 的行空间张成的子空间上，而这个子空间中的解恰好就是范数最小的解。
场景二：求解矩阵的伪逆 A⁺
矩阵的伪逆（也称为 Moore-Penrose 逆）是逆矩阵在不可逆或非方阵情况下的推广。它在求解上述最小二乘和最小范数问题时起着核心作用。
SVD 是计算伪逆最直接、最稳定的方法：
如果 A = UΣVᵀ，那么它的伪逆就是：
A⁺ = VΣ⁺Uᵀ
这与我们上面求解 x = A⁺b的公式完全一致。
场景三：求解病态问题或进行降噪/压缩
当一个矩阵 A​ 是“病态”的（即它的条件数很大，微小的输入变化会导致解的剧烈波动）时，直接用 A⁻¹计算会放大误差。
SVD 求解允许我们通过截断奇异值（Truncated SVD）来改善这个问题：
在计算伪逆 Σ⁺时，我们只保留前 k个最大的奇异值（k < r），而将剩下的较小奇异值设为零。
这样得到的近似解 x_approx = V_k Σ_k⁻¹ U_kᵀ b对数据中的噪声不敏感，起到了平滑和降噪的作用。
这在数据压缩（只保留最重要的特征）和主成分分析（PCA）中是核心步骤。