# ConvTranspose2d 转置卷积/反卷积

ConvTranspose2d 常被称为「转置卷积」或「反卷积」（注意：不是卷积的逆操作，只是维度逆过程），核心作用是：

+ 上采样：将小尺寸特征图放大为大尺寸（如 U-Net 解码器中 320×240→640×480）；
+ 特征恢复：在上采样的同时融合编码器的跳跃连接特征，保留车道线的空间细节；
+ 本质：通过「补零 + 步长扩张」的卷积操作，实现尺寸放大，而非简单插值（如双线性插值）。

## ConvTranspose2d 上采样核心原理

和普通卷积（下采样）的「窗口滑动→局部计算」不同，转置卷积的上采样逻辑是：

+ 输入补零：在输入特征图的像素之间填充（kernel_size-1）个 0；
+ 步长扩张：卷积核滑动步长 = 1，但等效于原卷积的步长逆操作；
+ 卷积计算：用普通卷积计算，输出尺寸自然放大。

**关键尺寸计算公式**

```
输出尺寸 = (输入尺寸 - 1) × stride - 2×padding + kernel_size + output_padding
```

output_padding 用于微调尺寸，通常设 0，下文示例会说明

```python
torch.nn.ConvTranspose2d(
    in_channels,      # 输入通道数（如U-Net解码器输入64通道）
    out_channels,     # 输出通道数（如U-Net解码器输出32通道）
    kernel_size,      # 卷积核尺寸（常用2×2，实现2倍上采样）
    stride=1,         # 步长（常用2，对应2倍上采样）
    padding=0,        # 输入填充数（常用0或1，配合kernel_size=2）
    output_padding=0, # 输出填充数（微调尺寸，避免维度偏差）
    bias=True,        # 偏置项（通常和BatchNorm配合时设False）
    padding_mode='zeros'
)
```

## ConvTranspose2d 上采样实战示例（核心）

用最小化数值示例演示「2 倍上采样」过程（对应 U-Net 解码器中最常用的kernel_size=2, stride=2, padding=0）。

### 步骤 1：设定参数和输入

转置卷积层：

```python
ConvTranspose2d(in_channels=1, out_channels=1, kernel_size=2, stride=2, padding=0)
```

+ 输入特征图：1×1×2×2（batch=1, channel=1, H=2, W=2），数值如下：

    ```plaintext
    输入特征图（2×2）：
    [[1, 2, 3],
    [4, 5, 6],
    [7, 8, 9]]
    ```
+ 卷积核：2×2，数值为[[1,0],[0,2]]（简化计算，实际为可学习参数）。在 PyTorch 的 ConvTranspose2d中实际应用时会先旋转 180 度

### 步骤 2：转置卷积的上采样过程（可视化）

转置卷积的核心是「输入插零→卷积核滑动→计算」，具体：

1. 输入插零：在输入的每个像素之间插入（stride-1）=1 个 0，得到 5×5 的插零矩阵：

```plaintext
插零后输入（5x5）：
[1, 0, 2, 0, 3]
[0, 0, 0, 0, 0]
[4, 0, 5, 0, 6]
[0, 0, 0, 0, 0]
[7, 0, 8, 0, 9]
```

2. 补零 1 圈得到 B（7×7）：

```
[0, 0, 0, 0, 0, 0, 0]
[0, 1, 0, 2, 0, 3, 0]
[0, 0, 0, 0, 0, 0, 0]
[0, 4, 0, 5, 0, 6, 0]
[0, 0, 0, 0, 0, 0, 0]
[0, 7, 0, 8, 0, 9, 0]
[0, 0, 0, 0, 0, 0, 0]
```

3. 用旋转后的核做卷积

核旋转 180 度：[[1,0],[0,2]]→ [[2,0],[0,1]]

```python
O[0,0] = B[0,0]2 + B[1,1]1 = 0 * 2 + 1 * 1 = 1
O[0,1] = B[0,1]2 + B[1,2]1 = 0 * 2 + 0 * 1 = 0
O[0,2] = B[0,2]2 + B[1,3]1 = 0 * 2 + 2 * 1 = 2
O[0,3] = B[0,3]2 + B[1,4]1 = 0 * 2 + 0 * 1 = 0
O[0,4] = B[0,4]2 + B[1,5]1 = 0 * 2 + 3 * 1 = 3
O[0,5] = B[0,5]2 + B[1,6]1 = 0 * 2 + 0 * 1 = 0
O[1,0] = B[1,0]2 + B[2,1]1 = 0 * 2 + 0 * 1 = 0
O[1,1] = B[1,1]2 + B[2,2]1 = 1 * 2 + 0 * 1 = 2
O[1,2] = B[1,2]2 + B[2,3]1 = 0 * 2 + 0 * 1 = 0
O[1,3] = B[1,3]2 + B[2,4]1 = 2 * 2 + 0 * 1 = 4
O[1,4] = B[1,4]2 + B[2,5]1 = 0 * 2 + 0 * 1 = 0
O[1,5] = B[1,5]2 + B[2,6]1 = 3 * 2 + 0 * 1 = 6
O[2,0] = B[2,0]2 + B[3,1]1 = 0 * 2 + 4 * 1 = 4
O[2,1] = B[2,1]2 + B[3,2]1 = 0 * 2 + 0 * 1 = 0
O[2,2] = B[2,2]2 + B[3,3]1 = 0 * 2 + 5 * 1 = 5
O[2,3] = B[2,3]2 + B[3,4]1 = 0 * 2 + 0 * 1 = 0
O[2,4] = B[2,4]2 + B[3,5]1 = 0 * 2 + 6 * 1 = 6
O[2,5] = B[2,5]2 + B[3,6]1 = 0 * 2 + 0 * 1 = 0
O[3,0] = B[3,0]2 + B[4,1]1 = 0 * 2 + 0 * 1 = 0
O[3,1] = B[3,1]2 + B[4,2]1 = 4 * 2 + 0 * 1 = 8
O[3,2] = B[3,2]2 + B[4,3]1 = 0 * 2 + 0 * 1 = 0
O[3,3] = B[3,3]2 + B[4,4]1 = 5 * 2 + 0 * 1 = 10
O[3,4] = B[3,4]2 + B[4,5]1 = 0 * 2 + 0 * 1 = 0
O[3,5] = B[3,5]2 + B[4,6]1 = 6 * 2 + 0 * 1 = 12
O[4,0] = B[4,0]2 + B[5,1]1 = 0 * 2 + 7 * 1 = 7
O[4,1] = B[4,1]2 + B[5,2]1 = 0 * 2 + 0 * 1 = 0
O[4,2] = B[4,2]2 + B[5,3]1 = 0 * 2 + 8 * 1 = 8
O[4,3] = B[4,3]2 + B[5,4]1 = 0 * 2 + 0 * 1 = 0
O[4,4] = B[4,4]2 + B[5,5]1 = 0 * 2 + 9 * 1 = 9
O[4,5] = B[4,5]2 + B[5,6]1 = 0 * 2 + 0 * 1 = 0
O[5,0] = B[5,0]2 + B[6,1]1 = 0 * 2 + 0 * 1 = 0
O[5,1] = B[5,1]2 + B[6,2]1 = 7 * 2 + 0 * 1 = 14
O[5,2] = B[5,2]2 + B[6,3]1 = 0 * 2 + 0 * 1 = 0
O[5,3] = B[5,3]2 + B[6,4]1 = 8 * 2 + 0 * 1 = 16
O[5,4] = B[5,4]2 + B[6,5]1 = 0 * 2 + 0 * 1 = 0
O[5,5] = B[5,5]2 + B[6,6]1 = 9 * 2 + 0 * 1 = 18
```

### 步骤 3：最终输出（4×4，实现 2 倍上采样）

```plaintext
输出特征图（6×6）：
[[ 1,  0,  2,  0,  3,  0],
 [ 0,  2,  0,  4,  0,  6],
 [ 4,  0,  5,  0,  6,  0],
 [ 0,  8,  0, 10,  0, 12],
 [ 7,  0,  8,  0,  9,  0],
 [ 0, 14,  0, 16,  0, 18]]
```

### 测试代码

```python
import torch
import torch.nn as nn

conv = nn.Conv2d(
    in_channels = 1,
    out_channels = 1,
    kernel_size = 2,
    stride = 2,
    padding = 1,
    bias = False
)

conv_trans = nn.ConvTranspose2d(
    in_channels = 1,
    out_channels = 1,
    kernel_size = 2,
    stride = 2,
    padding = 0,
    bias = False
)

conv.weight.data = torch.tensor([[[[1, 0], [0, 2]]]], dtype=torch.float32)
conv_trans.weight.data = torch.tensor([[[[1, 0], [0, 2]]]], dtype=torch.float32)

x = torch.tensor([[[[1, 2, 3], [4, 5, 6], [7, 8, 9]]]], dtype=torch.float32)

ct_output = conv_trans(x)
c_output = conv(x)

print("输入特征图形状：", x.shape)  # torch.Size([1, 1, 2, 2])
print("ct 输出特征图形状：", ct_output.shape)  # torch.Size([1, 1, 4, 4])（2倍上采样）
print("ct 输出特征图数值：\n", ct_output.detach().squeeze().numpy())

print("c 输出特征图形状：", c_output.shape) 
print("c 输出特征图数值：\n", c_output.detach().squeeze().numpy())
```